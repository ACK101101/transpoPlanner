{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import gc\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "\n",
    "def load_network(graph_file) -> nx.Graph:\n",
    "    \"\"\"loads in modified OSM graph\"\"\"\n",
    "    G_trans = ox.load_graphml(\n",
    "                graph_file,\n",
    "                node_dtypes={'idx':int, 'x':float, 'y':float, 'general0':float, 'general1':float, \n",
    "                            'general2':float, 'general3':float, 'general4':float},    \n",
    "                edge_dtypes={'u':int, 'v':int, 'speed':float, 'capacity':float, 'length':float,\n",
    "                             'general0':float, 'general1':float, 'general2':float, 'general3':float})\n",
    "    G_trans = G_trans.to_undirected()                                   # make undirected\n",
    "    return G_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./osm_dataset/raw/east.osm\n",
      "./osm_dataset/raw/copenhagen.osm\n",
      "./osm_dataset/raw/nairobi.osm\n",
      "./osm_dataset/raw/melbourne.osm\n",
      "./osm_dataset/raw/durham.osm\n",
      "./osm_dataset/raw/calgary.osm\n",
      "./osm_dataset/raw/jakarta.osm\n",
      "./osm_dataset/raw/manila.osm\n",
      "./osm_dataset/raw/la.osm\n",
      "./osm_dataset/raw/tehran.osm\n",
      "./osm_dataset/raw/hanoi.osm\n",
      "./osm_dataset/raw/seattle.osm\n",
      "./osm_dataset/raw/west.osm\n",
      "./osm_dataset/raw/kobe.osm\n",
      "./osm_dataset/raw/rio.osm\n",
      "./osm_dataset/raw/beirut.osm\n",
      "./osm_dataset/raw/istanbul.osm\n",
      "./osm_dataset/raw/delft.osm\n",
      "./osm_dataset/raw/taipei.osm\n",
      "./osm_dataset/raw/vienna.osm\n",
      "./osm_dataset/raw/bogota.osm\n",
      "./osm_dataset/raw/suwon.osm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "data_list = []\n",
    "for osm_path in glob.glob('./osm_dataset/raw/*'):\n",
    "    print(osm_path)\n",
    "    osm_graph = load_network(osm_path)\n",
    "    data = from_networkx(osm_graph, \n",
    "                        group_node_attrs=[\"idx\", \"general0\", \"general1\", \"general2\",\n",
    "                                        \"general3\",  \"general4\", \"x\", \"y\"], \n",
    "                        group_edge_attrs=[\"u\", \"v\", \"osmid\", \"general0\", \"general1\", \n",
    "                                        \"general2\", \"general3\", \"length\", \"speed\", \"capacity\"])\n",
    "    data.path = osm_path\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN config\n",
    "node_dim = 8\n",
    "edge_dim = 10\n",
    "erm_hidden_dim = 32\n",
    "action_dim = 4\n",
    "num_sample_actions = 4\n",
    "\n",
    "# DQN\n",
    "graph_dim  = 32\n",
    "hidden_dim = 32\n",
    "\n",
    "# Planner\n",
    "gamma = 0.99\n",
    "epsilon_start = 1.0\n",
    "epsilon_decay = 1000\n",
    "epsilon_min = 0.05\n",
    "batch_size = 48\n",
    "memory_size = 2000\n",
    "pop_size = 300\n",
    "episode_len = 24\n",
    "\n",
    "# Overall\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 1000\n",
    "num_episodes = 6\n",
    "num_runs = 10\n",
    "\n",
    "# Saving\n",
    "every_n_train_steps = 18\n",
    "val_every_k_epochs = 3\n",
    "log_every_k_steps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trans_infra.trans_infra.planner3 import DQNLightning\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./osm_dataset/raw/copenhagen.osm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/alexanderkumar/miniconda3/envs/graphs/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /Users/alexanderkumar/Desktop/transpoPlanner/transpoPlanner/checkpoints/planner3_v1 exists and is not empty.\n",
      "Restoring states from the checkpoint path at ./checkpoints/planner3_v1/last.ckpt\n",
      "\n",
      "  | Name       | Type                | Params\n",
      "---------------------------------------------------\n",
      "0 | edge_model | EdgeRegressionModel | 86.8 K\n",
      "1 | q_net      | DQN                 | 4.8 K \n",
      "2 | t_net      | DQN                 | 4.8 K \n",
      "3 | criterion  | MSELoss             | 0     \n",
      "---------------------------------------------------\n",
      "96.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "96.3 K    Total params\n",
      "0.385     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at ./checkpoints/planner3_v1/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded replay memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderkumar/miniconda3/envs/graphs/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/alexanderkumar/miniconda3/envs/graphs/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4a68df672a42cf8b4dc36702764d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b111117c264cd1a939e5046b415a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./osm_dataset/raw/tehran.osm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderkumar/miniconda3/envs/graphs/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "Epoch 29, global step 540: 'val_loss' reached 21.05246 (best 14.03883), saving model to '/Users/alexanderkumar/Desktop/transpoPlanner/transpoPlanner/checkpoints/planner3_v1/planner3_v1-epoch=29-val_loss=21.05.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with val step\n",
      "saving replay\n",
      "saving replay\n",
      "done with train step\n",
      "done with train step\n",
      "done with train step\n",
      "done with train step\n",
      "getting data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./osm_dataset/raw/kobe.osm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [02:53<00:00, 28.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with train step\n",
      "done with train step\n",
      "done with train step\n",
      "done with train step\n",
      "done with train step\n",
      "done with train step\n",
      "updated target model\n",
      " updated target model\n",
      "done with train step\n",
      "done with train step\n",
      "getting data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./osm_dataset/raw/beirut.osm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [02:54<00:00, 29.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with train step\n",
      "done with train step\n",
      "done with train step\n",
      "done with train step\n",
      "done with train step\n",
      "done with train step\n",
      "done with train step\n",
      "done with train step\n",
      "getting data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./osm_dataset/raw/seattle.osm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [03:31<00:00, 35.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create the DQNLightning module\n",
    "model = DQNLightning(node_dim, edge_dim, erm_hidden_dim, graph_dim, hidden_dim, action_dim, \n",
    "                     num_sample_actions, criterion, gamma, epsilon_start, epsilon_decay, epsilon_min, \n",
    "                     batch_size, memory_size, learning_rate, data_list, \n",
    "                     pop_size, episode_len, num_episodes, num_runs)\n",
    "\n",
    "# Configure the logger\n",
    "name = \"planner3\"\n",
    "version = 1\n",
    "logger = TensorBoardLogger('./logs/', name=name, version=version)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f'./checkpoints/{name}_v{version}',\n",
    "    filename=f'{name}_v{version}'+'-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=3, monitor='val_loss',\n",
    "    mode='min', verbose=True,\n",
    "    every_n_epochs=1, \n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer = pl.Trainer(logger=logger, max_epochs=1000, \n",
    "                    check_val_every_n_epoch=val_every_k_epochs,\n",
    "                    callbacks=[checkpoint_callback],\n",
    "                    log_every_n_steps=log_every_k_steps)\n",
    "\n",
    "trainer.fit(model, ckpt_path=f\"./checkpoints/{name}_v{version}/last.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9e47f3e75eb630de\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9e47f3e75eb630de\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir='./logs/'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
